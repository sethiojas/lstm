{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9294c691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./training.csv', encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39719b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                              tweet\n",
       "0          0  is upset that he can't update his Facebook by ...\n",
       "1          0  @Kenichan I dived many times for the ball. Man...\n",
       "2          0    my whole body feels itchy and like its on fire \n",
       "3          0  @nationwideclass no, it's not behaving at all....\n",
       "4          0                      @Kwesidei not the whole crew "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['sentiment', 'id', 'datetime', 'query', 'username', 'tweet']\n",
    "df = df.drop(['id', 'datetime', 'query', 'username'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0664cf97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Negative\n",
       "1    Negative\n",
       "2    Negative\n",
       "3    Negative\n",
       "4    Negative\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_sentiment = {0:'Negative', 4:'Positive'}\n",
    "def mapper(label):\n",
    "     return label_to_sentiment[label]\n",
    "df.sentiment = df.sentiment.apply(lambda x: mapper(x))\n",
    "df.sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d778ba2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dist = df.sentiment.value_counts()\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(dist.index, dist.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17e7a774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ojass\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88b9616d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>upset update facebook texting might cry result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>kenichan dived many times ball managed save 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>nationwideclass behaving mad see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>kwesidei whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                              tweet\n",
       "0  Negative  upset update facebook texting might cry result...\n",
       "1  Negative  kenichan dived many times ball managed save 50...\n",
       "2  Negative                   whole body feels itchy like fire\n",
       "3  Negative                   nationwideclass behaving mad see\n",
       "4  Negative                                kwesidei whole crew"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "import re\n",
    "text_cleaning_regex = \"@S+|https?:S+|http?:S|[^A-Za-z0-9]+\"\n",
    "\n",
    "def clean_tweets(text, stem=False):    \n",
    "    text = re.sub(text_cleaning_regex, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token in stop_words:\n",
    "            continue\n",
    "        if stem:\n",
    "            tokens.append(stemmer.stem(token))\n",
    "        else:\n",
    "            tokens.append(token)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df.tweet = df.tweet.apply(lambda x: clean_tweets(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "add272bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data size: 1279999\n",
      "Test Data size 320000\n"
     ]
    }
   ],
   "source": [
    "# Import functions from sklearn library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2,random_state=16)\n",
    "print(\"Train Data size:\", len(train_data))\n",
    "print(\"Test Data size\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bda88c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data.tweet)\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f3f8bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size : 565903\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary Size :\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b19038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# The tokens are converted into sequences and then passed to the pad_sequences() function\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(train_data.tweet),maxlen = 30)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(test_data.tweet),maxlen = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6789360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0      0      0 ...      0  68478    851]\n",
      " [     0      0      0 ...     11   1109    664]\n",
      " [     0      0      0 ... 188742    510    187]\n",
      " ...\n",
      " [     0      0      0 ...    121   1493    294]\n",
      " [     0      0      0 ...     78    273    615]\n",
      " [     0      0      0 ...     66  76815   3020]] [[     0      0      0 ...    310    219 137847]\n",
      " [     0      0      0 ...     63     64     63]\n",
      " [     0      0      0 ...    475    450    936]\n",
      " ...\n",
      " [     0      0      0 ...   1973   3013    171]\n",
      " [     0      0      0 ... 242501   1078    261]\n",
      " [     0      0      0 ...      0      0    713]] [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "labels = ['Negative', 'Positive']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_data.sentiment.to_list())\n",
    "y_train = encoder.transform(train_data.sentiment.to_list())\n",
    "y_test = encoder.transform(test_data.sentiment.to_list())\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "print(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8009f058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "# opening the downloaded glove embeddings file\n",
    "f = open('./glove.6B.300d.txt', encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    # For each line file, the words are split and stored in a list\n",
    "    values = line.split()\n",
    "    word = value = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' %len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a29038cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an matrix with zeroes of shape vocab x embedding dimension\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "# Iterate through word, index in the dictionary\n",
    "for word, i in word_index.items():\n",
    "    # extract the corresponding vector for the vocab indice of same word\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Storing it in a matrix\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d6d9f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "embedding_layer = tf.keras.layers.Embedding(vocab_size,300,weights=[embedding_matrix],\n",
    "                                          input_length=30,trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5032d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import various layers needed for the architecture from keras\n",
    "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# The Input layer \n",
    "sequence_input = Input(shape=(30,), dtype='int32')\n",
    "# Inputs passed to the embedding layer\n",
    "embedding_sequences = embedding_layer(sequence_input)\n",
    "# dropout and conv layer \n",
    "x = SpatialDropout1D(0.2)(embedding_sequences)\n",
    "x = Conv1D(64, 5, activation='relu')(x)\n",
    "# Passed on to the LSTM layer\n",
    "x = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "# Passed on to activation layer to get final output\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(sequence_input, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bc7fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "LR = 3e-4\n",
    "model.compile(optimizer=Adam(learning_rate=LR), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "ReduceLROnPlateau = ReduceLROnPlateau(factor=0.1,min_lr = 0.01, monitor = 'val_loss',verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bc793d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1250/1250 [==============================] - 1186s 943ms/step - loss: 0.5380 - accuracy: 0.7239 - val_loss: 0.4958 - val_accuracy: 0.7557 - lr: 3.0000e-04\n",
      "Epoch 2/3\n",
      "1013/1250 [=======================>......] - ETA: 3:53 - loss: 0.5032 - accuracy: 0.7512"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training = model.fit(x_train, y_train, batch_size=1024, epochs=3,\n",
    "                    validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
